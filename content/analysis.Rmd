---
title: Analysis
description:
toc: true
featuredVideo:
featuredImage: /images/analysis.png
draft: false
---

# Analyis Part 1

Data exploration and model creation of dataset 1
We are entering the exciting part of  this project, which is first the data exploration and transformation and cleaning as a foundation of model creation in the last part. The model is aimed to predict NBA players’ 3 pointers made in each season based on the 19-20 season. Remember, all the analysis and prediction is based on the dataset 1!!


## R Markdown
```{r echo=FALSE, include=FALSE}
#load libraries
library(readr)
library(dplyr)
library(ggplot2)
library(plotly)
library(reshape2)
library(caTools)
library(recipes)
library(MASS)
library(olsrr)
library(relaimpo)
```

```{r message=FALSE, warning=FALSE}
#load data into R
nba_data <- read_csv("../dataset-ignore/NBA Stats.csv")
head(nba_data) #glimpse of the data
```

# Data Preprocessing and Preparation

Before we enter the actual exploration, there are few data transformations, cleaning and filtering we have to make! First of all we want to filter out the player that has three pointers made per game in a season that is lower than 1.5. Since players are having an average that is lower than 1.5 three per game, he can not be counted as a shooter. Normally a player that is not a typical shooter can have their pointer percentages that are extremely low or extremely high! However, you may be asking if we are predicting NBA players’ three pointers made per season, why we care about the percentages, and this is because not only are their percentages extreme, but also they can not make threes consistently. Since we are predicting NBA players’ 3pm based on the current statistics, we want out data from players whose percentage is explainable with reasons.
Next cleaning for the data is removing the dollar sign for all the numbers for parameters “Salary” in the dataset so that R can read it. Finally, we noticed that R can not read ‘Height’ of NBA players, so we transform the numbers like 8-6 (stands for 6 feet 8) into inches through the function we wrote so that makes it readable for R.

```{r}
#filter to select players who made at least 1.5 3s per game
nba_data <- nba_data %>% 
  filter(`3pm` >= 1.5)
nba_data$Salary = nba_data$`2018/19`

#remove the $ sign
nba_data$Salary = as.numeric(gsub("[\\$,]", "", nba_data$Salary ))

#convert weight to kgs
nba_data$Weight = nba_data$Weight* 0.453592

```


```{r}
#player height is in character form, convert to height in feet

#create a function to do so:
playerHeight <- function(x) {
        x1 <- as.numeric(sub("-.*", "", x))
        x2 <- as.numeric(sub(".*-", "", x))
        (x1 * 12) + x2
}
#apply the function to the height data values
nba_data$Height <- playerHeight(nba_data$Height)

#select relevant variables into 1 data frame
nba_df = subset(nba_data, select = c(Age,gp,min,ast,oreb,dreb,fta, stl,Shoes,blk,tov,Salary,Height, Weight,`3pm`))

```


#Exploratory Data Analysis (EDA)
```{r}
#descriptive stats
summary(nba_df)
```

The descriptive statistic output shows the mean age of NBA players is approximately 27 years (27.04).
The oldest player is 42 years and the youngest is 19 resulting in a range of about 23 years. The mean
height is 77.77 inches (approximately 6.41 ft). The shortest NBA player is 6ft tall (72 inches) while the
tallest is 7ft tall (84 inches), translating to a range of 12 inches. With regard to player performance, the
maximum number of games a played is (gp) is 82 and the minimum is 58, and this variation could be
related to player performance whereby a high-performing player is highly prioritized in terms of games
allocation. The same logic applies to minutes played (MP). Our target variable is 3Pm, which is the
number of 3-point scores made per game. The mean 3-P score is 2.11, the minimum is 1.5 and the
maximum 3 point scores ever made by one player in one game is 5.11. The 75th quartile is 2.30, implying
that at least 25% of all NBA players made above 2.3 scores per game. This cohort may represent elite
players with consistently good performance, hence, sports organizations should focus on not to lose them
to rival teams.

We wanna first have  a glimpse of the data, as we generate the Min, Median, Mean and Max of some important parameters. The descriptive statistic output shows the mean age of NBA players is approximately 27 years (27.04). The oldest player is 42 years and the youngest is 19 resulting in a range of about 23 years. The mean height is 77.77 inches (approximately 6.41 ft). The shortest NBA player is 6ft tall (72 inches) while the tallest is 7ft tall (84 inches), translating to a range of 12 inches. With regard to player performance, the maximum number of games played is (gp) is 82 and the minimum is 58, and this variation could be related to player performance whereby a high-performing player is highly prioritized in terms of games allocation. The same logic applies to minutes played (MP).  Our target variable is 3Pm, which is the number of 3-point scores made per game. The mean 3-P score is 2.11, the minimum is 1.5 and the maximum 3 point scores ever made by one player in one game is 5.11. The 75th quartile is 2.30, implying that at least 25% of all NBA players made above 2.3 scores per game. This cohort may represent elite players with consistently good performance, hence, sports organizations should focus on not losing them to rival teams.

Then we want to have a more direct view of our ‘protagonist’, 3 pointers made. So we wanna generate a histogram  of distribution of 3 PM. 


```{r, fig.align='center',out.extra='angle=90'}
#histogram plots
ggplot(nba_df, aes(x =`3pm`))+
  geom_histogram(color = 'darkblue', fill ='lightblue')+
  ggtitle('Distribution of 3PM')+
  theme(plot.title = element_text(hjust = 0.5))

```

The histogram above illustrates the distribution of 3-p scores made (denoted as 3pm). Most NBA players’ ‘three pointers per game’ is around 1.5 to 2.5. Averagely speaking, if a player can hit 2 three pointers per game, it will be impressive. It is evident that distribution of 3P scores is skewed to the right, as evidenced by most values that lie on the left side of the chart. This means that most NBA players score fewer 3P field goals. However, we can discern the presence of outliers – a bar far away from the rest of other bars. This outlier represents NBA players with exceptionally high 3P scores compared to the general population of NBA players. We are more interested in the general population, and hence, it was worthwhile to remove the outliers to avoid skewing the performance of our model.


```{r fig.width=10, fig.align='center',out.extra='angle=90'}
#box plot of 3pm by shoes

ggplot(nba_data, aes(x = Shoes, y=`3pm`, fill=Shoes))+
  geom_boxplot(outlier.colour = 'red', notch = FALSE)+
  ggtitle('Box Plot of 3-Point Scores Made by Shoes Worn')+
  theme(plot.title = element_text(hjust = 0.5))

```
Figure 2


Figure 2 is a side-to-side boxplot of the dependent variable, 3pm, by shoe brand. There appears to be an association between shoe and player scoring, as evidenced by the variation in mean 3P scores. Players using under armor made the highest 3p scores, followed at a distance by Jordan, Adidas, Nike, Puma, and so on. It is interesting to see through this graph that when brand making deals with NBA stars, they have their tendencies. For AU, they are typically aiming guards, especially ones that can hit three consistently. Since they have Stephen Curry as their top star, we can see that they are trying to build cultures of their brand’s stars. Even the only big man they signed has a good 3 pointer percentage and makes!(Joel Embiid). It will be interesting to see other tendencies of other brands, but since it is not related to this project, we will not provide more details. At least, this statistical finding supports the inclusion of shoe brands as a predictor of the 3P score and checks whether the existing relationship is statistically significant.

```{r, fig.align='center',out.extra='angle=90'}
col_df <- nba_data %>% group_by(College)%>% summarize(Mean_3Pm= mean(`3pm`))
con_df <-nba_data %>% group_by(Country)%>% summarize(Mean_3Pm= mean(`3pm`))

plot_ly(col_df, x = ~College, y = ~Mean_3Pm, type = 'bar', text = text)
plot_ly(con_df, x = ~Country, y = ~Mean_3Pm, type = 'bar', text = text)
```

We wanna then take advantage of this data set that contains so many columns, so next we wanna examine the relationships between all these variables with ‘3pm’. We generate the histogram of 3pm that categorizes NBA players from different colleges! It is impressive that Davison college is off the chart thanks to the Best shooter of all time, Stephen Curry! Arizona University is also pretty high, and that is thanks to one of the best scorers in the league James harden! It is really fun to see how these parameters are working together. However, the parameter college is not a parameter we will be using in the prediction since one of the colleges basically only represents 1 player, this stats is too specific and can not be a predictive parameter of the model.

The next interactive chart is to examine the relationship between Mean 3pm with the country, the parameter 3pm is facing the same problem as College, though a little bit better. However, the parameter country is still not qualified to be part of the prediction model since players are too spread into these categories, but also because intuitively, the country cannot contribute to players' three pointer skills.

```{r fig.height=7, fig.width=10, fig.align='center',out.extra='angle=90'}
#correlation analysis
cor_df <- subset(nba_df, select =-c(Shoes))
cor.mat  <- round(cor(cor_df),3) #correlation matrix
cormat_melt <- melt(cor.mat)

corr_heatmap <- ggplot(data = cormat_melt, aes(x = Var1, y=Var2, label = value, fill = value))+
  geom_tile()
corr_heatmap+
  geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)
```
Figure 5 Correlation Matrix

The correlation plot above identifies the direction and magnitude of association between pairs of
variables in our dataset. It is evident that there is a moderate positive relationship between 3P scores and
assists (ast, r = 0.262), 3p scores and minutes played (min, r = 0.41), 3p scores and steals (stl, r =0.349),
and 3p scores and age (r=0.221). It is interesting that correlation between player height and 3p scores is
negative (r = -0.088). However, further analysis indicate that the correlation coefficient is not statistically
different from zero, hence, height and 3p scores are unrelated.
We can also identify the presence of multicollinearity issues in our dataset, as evidenced by the
high correlation between some of the pairs of independent variables. For example, there is a high
correlation between assists (ast) and turnover (tov, r = 0.858). A possible approach to address this issue is
to remove one of the variables from each pair. We included a cut-off of 0.85 in our regression model
function to eliminate one of the independent variables that is highly correlated, preferably one with a
higher p-value.

#Interactive Charts
```{r, fig.align='center',out.extra='angle=90'}
fig <- plot_ly(data = nba_df, x = ~Height, y = ~`3pm`)
fig <- fig %>%layout(title = 'A Scatter Plot of 3pt Percentage against Height')
fig
```

We then generate a graph between 3pm and Height, the idea behind it is that players were assigned roles and specified their skills according to their heights, so intuitively, players that are shorter(who players mostly guards) could potentially have better three pointer skills. However, after generating these graphs, we cannot discern any relationship between 3pm and height, as the points appear random, with no visual pattern to indicate association between player’s height and 3-points scores made. From my speculation, this is because in modern days, players are having more comprehensive skill bags. More and more 7 foot players are initiating offense outside the three pointer line. As in before, 7 foot players always stay in the paint.


```{r, fig.align='center',out.extra='angle=90'}
fig.2 <- plot_ly(data = nba_data, x = ~`3pm`, y = ~`3pa`, 
        title = "S")
fig.2 <- fig.2 %>%layout(title = 'A Scatter Plot of 3pt Percentage against 3pt Made')
fig.2
```

```{r}
fig.3 <- plot_ly(data = nba_data, x = ~eff, y = ~`3pm`)
fig.3 <- fig %>%layout(title = 'A Scatter Plot of 3pt Percentage against Efficiency')
fig.3
```
Figure 4 Scatterplot (3pm vs Height)

We cannot discern any relationship between 3pm and height, as the points appear random, with no visual
pattern to indicate association between player’s height and 3-points scores made.

```{r, fig.align='center',out.extra='angle=90'}

fg <- plot_ly(data = nba_df, x = ~Age, y = ~`3pm`)
fg %>%layout(title = 'A Scatter Plot of 3pt Percentage against Player Age')
```
Figure 3 Scatter plot (3pm vs Age)

The scatterplot above visualizes the relationship between player score performance (3p scores per game)
by age. There appears to be a positive relationship between age and 3-points scoring. A player is at prime
in mid 20s and early 30s, and start to decline as he approaches 35 years.

#Full Model
```{r}
set.seed(123)
#define 3pm as y
nba_df$y = nba_df$`3pm`
#remove 3pm
nba_df = subset(nba_df, select = -(`3pm`))

#use 70% of dataset as training set and 30% as test set
sample <- sample.split(nba_df$y, SplitRatio = 0.8)
train  <- subset(nba_df, sample == TRUE)
test   <- subset(nba_df, sample == FALSE)

rec <- recipe(
  y ~.,
  data = train)%>%
  step_normalize(Salary, Age, gp, min, Height, Weight)%>%
  step_corr(all_numeric_predictors(), threshold = 0.85)%>%
  step_dummy(Shoes)

log.rec.prep <- prep(rec, training = train) #prepare recipe

train_set <- log.rec.prep %>% #replicate data transformation results to testing data
  bake(new_data = NULL)
full.model = lm(y~., data = train_set)
summary(full.model)

```
#Model Selection

Optimal Model: Based on the Lowest AIC Value

Figure 6
Figure 6 shows the final model containing best subsets of variables for predicting
offensive performance of an NBA player, measured by 3-point scores made (3pm).The selection
of the variables to include in final model was based on the lowest AIC value. We chose AIC as
our ideal model selection criterion because it results in the selection of the model that bests fits
the data and it is moderately tolerant compared to BIC (Yang &amp; Berdine, 2015). The selected
variables include age, games played (gp), minutes played (min), assist (ast), offensive rebounds
(oreb), steals (stl), free throws (fta), and shoes. The coefficient on age, min, fta, stl, shoes (new
balance and under armour) are statistically significant at 0.01 because their corresponding p-
values is less than 0.01 (see figure 6). To illustrate a few variables, the coefficient on age is
0.1976, implying that an increase in player age by one year is associated with an increase in 3pt
scores by 0.2, presuming other factors are held constant. Furthermore, an NBA player wearing
under armour during play is likely to make more 3pt scores compared to a player wearing other
brands, such as Under Armour, or Adidas. The resulting equation for predicting player
performance is:
Y i = 1.9627 + 0.1976X 1 + 0.091X 2 + 0.294X 3 - 0.165X 4 – 0.254X 5 – 0.152X 6 + 0.474X 7 – 0.148X 8
-1.10X 9 + 1.139X 10 , where X 1 denotes age, X 2 is gp, X 3 is min, X 4 is ast, X 5 is oreb, X 6 is fta, X 7 is
stl, X 8 is height, X 9 is Shoes_New.Balance and X 10 is Shoes.Under.Armour.
The global F test informs us to reject the null hypothesis all coefficients are equal to zero
because there is sufficient evidence to indicate that at least one covariate is statistically different from
zero, F (10, 55) = 6.503, p-value = 1.566 e-06 &lt;0.05. Lastly, the adjusted R-squared is 0.4585, implying
that this final model explains at least 45.9% of the variation in 3-P scores across NBA players.

Predictive Performance on Testing Set

Figure 7 is a scatter plot of actual vs fitted values of 3-points scores made. It is evident
that most values lie close to the regression line and are within the 95% confidence level region.
However, some of the values we either under-predicted or over-predicted, as evidenced by the
points lying far away from the regression line and outside the grey region. The calculated RMSE
is 0.4868, which is relatively close to 0, hence, the model did great in terms of predicting player
performance.

```{r}
#ols_step_best_subset(full.model)
```
#final model
```{r}
set.seed(123)
final.model <- stepAIC(full.model, direction ='backward', trace = FALSE)
reg.summary = summary(final.model)
reg.summary
```

```{r, fig.align='center',out.extra='angle=90'}
 #make predictions on testing dataset using the full model
testing_set <- bake(log.rec.prep, test)
testing_set$fitted = predict(final.model, newdata = testing_set)

ggplot(testing_set, aes(x = y, y=fitted))+
  geom_point()+
  geom_smooth(method='lm')+
  ggtitle('fitted vs actual plot')+
  ylab('Actual')+
  xlab('Fitted')+
  theme(plot.title = element_text(hjust = 0.5))

```
Figure 7

```{r}
#RMSE
sqrt(mean((testing_set$y - testing_set$fitted)^2))#print RMSE
```
```{r}
#relative importance of predictors
rel_imp <- calc.relimp(final.model, type = c("lmg"), rela = TRUE)
rel_imp
```


Relative Importance Based on the output below, free throws made (fta) and minutes played (min) are ranked as the important predictor of 3-P scores, followed closely by Shoes (Under Armour), then age and steals (stl). Scouts should pay more attention to these metrics when scouting for NBA players to play in the professional league as it will guarantee positive returns on their investments.

As a conclusion of the model we can see that some of the parameters are affecting the final result in a more significant way. Like ‘minutes played on the court’ which is min in the model, increases 3 pointers per game averagely 0.3 per minutes, and ‘stl’, which stands for average steal, increases 3 pointers per game averagely 0.47 per steal. As I stated before, these are important parameters for teams or scouts to look at.

For the model, although we think it did not do badly on predicting 3pm, we still think there are improvements. To improve, we first need a data set that contains data for more NBA players. Secondly, we decided to use another parameter ‘3p’, which shows the number of threes players made over a season. This is to avoid filtering out players that hit lower than 1.5 three per game. We now think all the data matters, if a player hits more three than other players, no matter how many games he plays, it has its value and significance behind it.  That’s why we have to introduce our second data set! In our model 2 we use dataset 2 to predict the number of total three pointers made for each player with different parameters.(please see introduction of dataset2 in Data page)


# Analysis Part 2

```{r}
#if(!require(installr)) {
#install.packages(installr); require(installr)} #load / install+load installr
# using the package:
#updateR()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
#update.packages(ask = FALSE)
#install.packages("lifecycle")
#install.packages(tidymodels)
#install.packages("rsample")
library(readr)
library(readxl)
library(tidyr)
library(tidymodels)
library(dplyr)
library(tidyverse)
library(fastDummies)
library(reshape2)
library(ggplot2)
library(caTools)
library(relaimpo)
library(MASS)
```

```{r message=FALSE, warning=FALSE}
player_df <- read_excel("../dataset-ignore/19-20 palyer total (1).xlsx")
head(player_df)
```
# Data Preparation 
```{r}

play_num = subset(player_df, select = -c(Player, Rk,Tm,`Player-additional`,GS,FG, FGA,`2P`,`3PA`,`2PA`,`2P%`, `3P%`, `eFG%`, `FG%`,FT, FTA,TRB, PTS))
play_num <- drop_na(play_num)


length(play_num)
```

```{r message=FALSE, warning=FALSE}
dummy <- dummy_cols(play_num, select_columns = c("Pos"), remove_first_dummy = TRUE)
model_data <- subset(dummy, select = -c(Pos))
```

```{r}

num_data <- play_num %>% dplyr::select(where(is.numeric))
```

# Exploratory Data Analysis

```{r}

summary(num_data)
```

Table 1

The descriptive statistic output shows the mean age of NBA players is approximately 26 years (25.83).
The oldest player is 43 years and the youngest is 19 resulting in a range of about 25 years. The maximum
number of games a player has started (G) is 74 and the minimum is 1, and this variation could be related
to player performance whereby a high-performing player is prioritized. The same logic applies to minutes
played per game (MP). Our target variable is 3P, which is the number of 3-point field goals per game.
The mean 3-P score is 46.07, the minimum is 0 and the maximum is 299 per game. The 75th quartile is
201, implying that at least 25% of all NBA players score make about 70 3P scores per game. This cohort
may represent elite players with consistently good performance, hence, sports organizations should focus
on not to lose them to rival teams
The histogram below illustrates the distribution of 3P scoring. It is evident that distribution of 3P scores is
skewed to the right, as evidenced by most values that lie on the left side of the chart. This means that most
NBA players score fewer 3P field goals. However, we can discern the presence of outliers – a bar far
away from the rest of other bars. This outlier represents NBA players with exceptionally high 3P scores
compared to the general population of NBA players. We are more interested in the general population,
and hence, it was worthwhile to remove it to avoid skewing the performance of our model.

```{r, fig.align='center',out.extra='angle=90'}

hist(num_data$`3P`, main = " Distribution of 3P", xlab = 'bins')
```

Figure 1 Distribution of 3P Scores

```{r fig.height=8, fig.align='center',out.extra='angle=90'}
boxplot(play_num$`3P`~ play_num$Pos, 
        main = ' A Boxplot of 3 Point Scoring by Player Position',
        ylab = '3 Point Scoring (3P)', xlab = 'Player Position', col = 'yellow', border = 'brown')
```

Figure 2 Side-to-Side Boxplot of 3 Point Scores by Position

The boxplot above captures the distribution of 3-point scores by player position. Based on the
plot, we can discern a significant difference in 3P scores across player positions, with SF-PF registering
the highest mean 3P scores, followed at distance by SF-FG, and SG-PG. This finding supports the
inclusion of player position as a predictor of the 3P score and checks whether the existing relationship is
statistically significant.

```{r, fig.align='center',out.extra='angle=90'}
cormatrx  <- round(cor(num_data),3) 
cormat_melt <- melt(cormatrx)

corr_heatmap <- ggplot(data = cormat_melt, aes(x = Var1, y=Var2, label = value, fill = value))+
  geom_tile()
corr_heatmap+
  geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)
```
```{r}

set.seed(1)

sample <- sample.split(model_data$`3P`, SplitRatio = 0.7)
train  <- subset(model_data, sample == TRUE)
test   <- subset(model_data, sample == FALSE)
```

Figure 3 Correlation Plot

The correlation plot above identifies the direction and magnitude of association between pairs of variables
in our dataset. It is evident that there is a moderate positive relationship between 3P scores and games
played (G, r = 0.644), 3P scores and assists per game (AST, r = 0.613), 3P scores and turnover per game
(TOV, r = 0.667), and a strong positive relationship between 3P scores and games played (G, r=0.773).
We can also identify the presence of multicollinearity issues in our dataset, as evidenced by the high
correlation between pairs of independent variables. For example, there is a high correlation between
minutes played (MP) and personal fouls per game (PF, r = 0.897), turnover per game (TOV) and MP (r =
0.853), assist per game (AST) and turnover per game (TOV, r = 0.897). A possible approach to address
this issue is to remove one of the variables from each pair. We included a cut-off of 0.85 in our regression
model funciton to eliminate one of the independent variables that are highly correlated, preferably one
with a higher p-value.

# Data Transformation

It is worthwhile to note that issues such as missing values and outliers were addressed by removing rows
containing NA and extreme values. Our next step is to perform data transformation. Firstly, we performed
dummy encoding on our only categorical data, player position, using the dummy_cols () function and
removed the first dummy column to avoid the multicollinearity issue. Secondly, variables, which contain

large values, such as Age, STL (steals per game), MP (minutes played), and BLK (blocks per game) were
normalized. Most importantly, all these transformations, including splitting data into training sets were
done at once using the recipe function in R and the results were also mirrored to the testing data using the
bake function.

# Optimal Model: Based on the Lowest AIC Value

```{r}
rec <- recipe(
  `3P` ~.,
  data = train)%>%
  step_normalize(Age, STL, MP, BLK)%>%
  step_corr(all_numeric_predictors(), threshold = 0.85)
```


```{r message=FALSE, warning=FALSE}
log.rec.prep <- prep(rec, training = train)

train_set <- log.rec.prep %>% 
  bake(new_data = NULL)
l.model = lm(`3P`~., data = train_set)
summary(l.model)
```

Figure 4 Final Model

While all 25 predictor variables namely, age, G, MP, STL, FT%, ORB, AST, BLK, TOV, PF, and
POS (14 dummy variables) were in the model, the StepAIC selected only 8 variables to statistically
significant at 0.05 and with the lowest AIC value. The selected variables include G, FT%, ORB, AST,
Pos_PG and Pos_SG. The coefficient on G is 0.9795, implying that a unit increase in the number of
games played increases 3 points by at least 0.97, approximately 1, presuming all other factors are held
constant. The coefficient on Pos_SG (SG = 1, not SG = 0) is 7.993, implying that NBA players in SG
(shooting guard) position score 8 3-P scores higher than all other positions, when other factors are also
held constant. In contrast, NBA players in PG positions score 13.60 (approximately 14) less 3P scores

compared to players in other positions. The global F test informs us to reject the null hypothesis all
coefficients are equal to zero because there is sufficient evidence to indicate that at least one covariate is
statistically different from zero, F (8, 433) = 116.2, p-value = 2.2e-16 &lt;0.05. Lastly, the adjusted R-
squared is 0.6763, implying that this final model explains at least 67.63% of the variation in 3-P scores
across NBA players. The resulting RMSE from prediction on test data is 30.583.

```{r}
 
testing_set <- bake(log.rec.prep, test)
test[1:10, names(testing_set)]

fitted = predict(l.model, newdata = testing_set)
actuals = as.numeric(testing_set$`3P`)

sqrt(mean((actuals - fitted)^2))
```

```{r}

l.model.fin <- lm(`3P` ~., data = train_set) %>%
  stepAIC(trace = FALSE)

summary(l.model.fin)
```

```{r message=FALSE, warning=FALSE}
 
testing_set <- bake(log.rec.prep, test)
test[1:10, names(testing_set)]

fitted = predict(l.model.fin, newdata = testing_set)
actuals = as.numeric(testing_set$`3P`)

sqrt(mean((actuals - fitted)^2))
```
```{r, fig.align='center',out.extra='angle=90'}

plot(fitted,
     xlab = "Predicted Values",
     ylab = "Observed Values")+
  geom_point()+
abline(a = 0,                                     
       b = 1,
       col = "red",
       lwd = 2)

```



```{r, fig.align='center',out.extra='angle=90'}

rel_imp <- calc.relimp(l.model.fin, type = c("lmg"), rela = TRUE)
boo_rslts <- boot.relimp(l.model.fin, b=1000)
ci <- booteval.relimp(boo_rslts, norank = T)
plot(ci)
```

Figure 5 Relative Importance

Based on the bar chart, games played (G) are ranked as the important predictor of 3-P scores, followed closely by AST (number of assists), then STL (steals per game), (DRB) defensive, and (ORB) offensive rebounds. Scouts should pay more attention to these characteristics when scouting for NBA players to play in the professional league as it will guarantee positive returns on their investments.

To conclude on the model, we think that the method of multiple linear regression in these two models are not different, we all first prepare the recipe for training and testing, and we all select models based on the lowest AIC value. What’s important is that we applied the different dataset! For dataset 2, although it has fewer columns than dataset1, it is obviously more extensive in terms of number of players, and we think it is probably according to the Law of large numbers, since the larger the observation, the data will be more approximated to a certain distribution. The Next change is that we changed our parameter from three pointers made per game to total three pointers made per season. This is because we decide that all value matters for this model, and we don’t have to filter out the players that made 1.5 three per game this way. 

As for the question, how will the Celtics change their offense settings? Well, this is a really comprehensive question and our project can only answer a little part of it. If they aim to improve a player's total three pointer made in a season, the parameter assist and steal is really important and intuitively this can have a lot of explanation. For example, players that are good at steals are creating more offensive chances or open three chances by initiating fast break after the steal, and so that they can have more three than the other. 

In the end, I hope you enjoy our analysis and prediction on 3 pointers of NBA players, and hope we can provide a little bit of insight that is different from normal NBA media on social media!


